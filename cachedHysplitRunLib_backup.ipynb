{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# library imports\n",
    "import datetime, dateutil, enum, fcntl, hashlib, re, requests, io, json, os, threading, traceback, glob, gzip, shutil\n",
    "from jinja2 import Template\n",
    "from sqlitedict import SqliteDict\n",
    "from filelock import Timeout, FileLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "dispersionCachePath = '/projects/9ab71616-fcde-4524-bf8f-7953c669ebbb/air-src/linRegModel/dispersionCache'\n",
    "easternTZ = dateutil.tz.gettz('America/New_York')\n",
    "\n",
    "\n",
    "def parse_eastern(date):\n",
    "    return dateutil.parser.parse(date).replace(tzinfo=easternTZ)\n",
    "\n",
    "\n",
    "# The menu is divided into two sections. In each case the value of the INITD namelist parameter is being set. In the upper\n",
    "# portion of the menu, the model is configured as either a full 3D particle or puff model, or some hybrid combination of\n",
    "# the two. The released particles or puffs maintain their mode for the entire duration of the simulation. Valid options are:\n",
    "# 0 - 3D particle horizontal and vertical (DEFAULT)\n",
    "# 1 - Gaussian-horizontal and Top-Hat vertical puff (Gh-THv)\n",
    "# 2 - Top-Hat-horizontal and vertical puff (THh-THv)\n",
    "# 3 - Gaussian-horizontal puff and vertical particle distribution (Gh-Pv)\n",
    "# 4 - Top-Hat-horizontal puff and vertical particle distribution (THh-Pv)\n",
    "# Introduced with the September 2004 version are mixed mode model calculations, where the mode can change during\n",
    "# transport depending upon the age (from release) of the particle. A mixed-mode may be selected to take advantage of the\n",
    "# more accurate representation of the 3D particle approach near the source and the smoother horizontal distribution\n",
    "# provided by one of the hybrid puff approaches at the longer transport distances. In a long-range or regional puff\n",
    "# simulation, where the concentration grid may be rather coarse, puffs may pass between concentration sampling nodes\n",
    "# during the initial stages of the transport, a stage when the plume is still narrow. Using mode #104 would start the\n",
    "# simulation with particles (and concentration grid cells) and then switch to puff mode (and concentration sampling\n",
    "# nodes) when the particles are distributed over multiple concentration grid cells. Valid options are:\n",
    "# 103 - 3D particle (#0) converts to Gh-Pv (#3)\n",
    "# 104 - 3D particle (#0) converts to THh-Pv (#4)\n",
    "# 130 - Gh-Pv (#3) converts to 3D particle (#0)\n",
    "# 140 - THh-Pv (#4) converts to 3D particle (#0)\n",
    "# 109 - 3D particle converts to grid (global model)\n",
    "\n",
    "# Hysplit online defaults to mode 104 (auto-switch from 0 to 4)\n",
    "# Hysplit manual says default is 0\n",
    "\n",
    "\n",
    "class InitdModelType(enum.Enum):\n",
    "    ParticleHV = 0\n",
    "    GaussianH_TopHapV = 1\n",
    "    TopHatHV = 2\n",
    "    GaussianH_ParticleV = 3\n",
    "    TopHatH_ParticleV = 4\n",
    "    ParticleHV_to_GaussianH_ParticleV = 103\n",
    "    ParticleHV_to_TopHatH_ParticleV = 104\n",
    "    GaussianH_ParticleV_to_ParticleHV = 130\n",
    "    TopHatH_ParticleV_to_ParticleHV = 140\n",
    "    ParticleHV_to_Grid = 109\n",
    "\n",
    "class HysplitModelSettings:\n",
    "    def __init__(self,\n",
    "                 initdModelType=InitdModelType.ParticleHV,\n",
    "                 hourlyPardump=False):\n",
    "        if isinstance(initdModelType, int):\n",
    "            print(\n",
    "                'Consider using InitdModelType enum for HysplitModelSettings')\n",
    "            initdModelType = InitdModelType(int)\n",
    "        self.initdModelType = initdModelType\n",
    "        self.hourlyPardump = hourlyPardump\n",
    "\n",
    "    def __str__(self):\n",
    "        ret = '<HMS'\n",
    "        ret += ' initd=%d' % self.initdModelType.value\n",
    "        if self.hourlyPardump:\n",
    "            pardumpMins = 60\n",
    "        else:\n",
    "            pardumpMins = 1\n",
    "        ret += ' pardump=%dm' % pardumpMins\n",
    "        ret += '>'\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class DispersionSource:\n",
    "    # minHeight and maxHeight are in meters\n",
    "    # area is in square meters\n",
    "    def __init__(self, name, lat, lon, minHeight, maxHeight, areaSqM=0):\n",
    "        assert(isinstance(name, str))\n",
    "        self.name = name\n",
    "\n",
    "        assert(-90 <= lat and lat <= 90)\n",
    "        self.lat = round(lat, 6)\n",
    "\n",
    "        assert(-180 <= lon and lon <= 180)\n",
    "        self.lon = round(lon, 6)\n",
    "\n",
    "        assert(0 <= minHeight and minHeight <= maxHeight)\n",
    "        self.minHeight = minHeight\n",
    "\n",
    "        assert(maxHeight <= 1000)\n",
    "        self.maxHeight = maxHeight\n",
    "\n",
    "        assert(areaSqM >= 0)\n",
    "        self.areaSqM = areaSqM\n",
    "\n",
    "    def cachePath(self):\n",
    "        path = '%.6f,%.6f_%g-%g' % (self.lat, self.lon, self.minHeight, self.maxHeight)\n",
    "        if self.areaSqM > 0:\n",
    "            path += '_%g' % self.areaSqM\n",
    "        return path\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "assert(DispersionSource(name='Test', lat=40.123456789, lon=-79.123456789, minHeight=10, maxHeight=50).cachePath() == '40.123457,-79.123457_10-50')\n",
    "assert(DispersionSource(name='Test', lat=40.123456789, lon=-79.123456789, minHeight=10, maxHeight=50, areaSqM=100).cachePath() == '40.123457,-79.123457_10-50_100')\n",
    "\n",
    "class CachedDispersionRun:\n",
    "    # input:\n",
    "    #    source -- DispersionSource representing lat/lon and altitude min/max of emission source\n",
    "    #    runStartLocal -- beginning of emission, in local timezone\n",
    "    #    emitTime -- length of emission, in hours\n",
    "    #    runTime -- length of simulation, in hours\n",
    "    #    fileName -- file name of binary results file\n",
    "    def __init__(self, source, runStartLocal, emitTimeHrs, runTimeHrs, hysplitModelSettings,\n",
    "                 fileName='cdump', hysplitLoc='/opt/hysplit/exec/',\n",
    "                 verbose=False):\n",
    "        try:\n",
    "            assert(source)\n",
    "            self.source = source\n",
    "\n",
    "            assert(runStartLocal)\n",
    "            self.runStartLocal = runStartLocal\n",
    "            self.runStartUtc = runStartLocal.astimezone(dateutil.tz.tzutc())\n",
    "\n",
    "            msg = 'CachedDispersionRun start=%s' % self.runStartLocal\n",
    "            if self.runStartLocal.tzinfo != self.runStartUtc.tzinfo:\n",
    "                msg += ' (%s)' % (self.runStartUtc)\n",
    "\n",
    "            msg += ' emitTime=%dh runTime=%dh initdModelType=%s source=%s' % (emitTimeHrs, runTimeHrs, repr(hysplitModelSettings.initdModelType), source)\n",
    "\n",
    "            assert(emitTimeHrs)\n",
    "            self.emitTimeHrs = emitTimeHrs\n",
    "\n",
    "            assert(runTimeHrs)\n",
    "            self.runTimeHrs = int(runTimeHrs)\n",
    "\n",
    "            self.initdModelType = hysplitModelSettings.initdModelType\n",
    "\n",
    "            self.verbose= verbose\n",
    "            if self.verbose:\n",
    "                sys.stdout.write(msg + '\\n')\n",
    "\n",
    "            self.logfile = None\n",
    "\n",
    "            self.hourlyPardump = hysplitModelSettings.hourlyPardump\n",
    "\n",
    "            if not os.path.exists(self.path()) and self.hourlyPardump:\n",
    "                self.hourlyPardump = False\n",
    "                if os.path.exists(self.path()):\n",
    "                    if self.verbose:\n",
    "                        sys.stdout.write('CachedDispersionRun -- found minutely pardump version, overriding hourlyPardump to be False\\n')\n",
    "                else:\n",
    "                    self.hourlyPardump = True\n",
    "\n",
    "        except AssertionError:\n",
    "            _, _, tb = sys.exc_info()\n",
    "            traceback.print_tb(tb) # Fixed format\n",
    "            tb_info = traceback.extract_tb(tb)\n",
    "            filename, line, func, text = tb_info[-1]\n",
    "\n",
    "            print('An error occurred on line {} in statement {}'.format(line, text))\n",
    "            exit(1)\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.hysplitLoc = hysplitLoc\n",
    "        self.runHr = int(runTimeHrs)\n",
    "        self.runMin = int((runTimeHrs - int(runTimeHrs))*60)\n",
    "\n",
    "        self.fNames = self.fetchWeatherFiles()\n",
    "\n",
    "    # Assert this run has all files associated with successful completion, e.g. cdump\n",
    "    def assertComplete(self):\n",
    "        errs = []\n",
    "        if not os.path.exists(self.cdumpPath()):\n",
    "            errs.append('cdump file %s should exist, but does not' % self.cdumpPath())\n",
    "        if errs:\n",
    "            raise Exception('Errors found in HYSPLIT directory %s: %s' % (self.path(), '; '.join(errs)))\n",
    "\n",
    "    def findOrRun(self):\n",
    "        if not os.path.exists(self.path()):\n",
    "            self.run()\n",
    "            self.assertComplete()\n",
    "        else:\n",
    "            self.vlog('Hysplit run at location %s already complete.' % self.path())\n",
    "            # Force uncompressing of PARDUMP\n",
    "            # Randy commented Feb 22 ... do we still need this here or can we move to where we actually need to read PARDUMP?\n",
    "            # self.getUncompressedPardump()\n",
    "            self.assertComplete()\n",
    "        return(self.path())\n",
    "\n",
    "    # Called internally.  Make sure we aren't already completed or in progress somewhere else before calling this method?\n",
    "    def run(self):\n",
    "        # Short circuit if already done\n",
    "        if os.path.exists(self.path()):\n",
    "            return(self.path())\n",
    "\n",
    "        # Create parent directory of lock\n",
    "        os.makedirs(os.path.dirname(self.path()),exist_ok=True) #if two threads run concurrently, allow this call to fail silently\n",
    "        # Create and hold lockfile\n",
    "        lockfilePath = self.path() + '.lock'\n",
    "        lock = FileLock(lockfilePath)\n",
    "        with lock:\n",
    "            # Delete old temp directory if it exists (need to delete tmpPaths with different pids)\n",
    "            if os.path.exists(self.tmpPath()):\n",
    "                self.log('Deleting old temp directory %s' % self.tmpPath())\n",
    "                shutil.rmtree(self.tmpPath())\n",
    "            if os.path.exists(os.path.join(self.path(),'cdump')):#short circuit if this is the second process to acquire the FileLock, and thus the run is complete\n",
    "                return(self.path())\n",
    "\n",
    "            os.makedirs(self.tmpPath())\n",
    "            self.logfile = open(self.tmpPath() + '/log.txt', 'w')\n",
    "            self.makeSetup()\n",
    "            self.makeASC()\n",
    "            self.makeControl()\n",
    "            self.vlog('Running dispersion, path %s, settings %s' % (self.tmpPath(), self.settingsAsString()))\n",
    "            try:\n",
    "                # TODO: have the HYSPLIT subprocess chdir instead of the python parent\n",
    "                self.runDispersion()\n",
    "                self.vlog('SUCCESS for dispersion run: %s' % self.tmpPath())\n",
    "            except Exception as e:\n",
    "                self.log('Received exception %s during DispersionRun' % e)\n",
    "                self.log('Run directory: %s' % self.tmpPath())\n",
    "                self.log('Settings: %s' % self.settingsAsString())\n",
    "                raise\n",
    "            try:\n",
    "                os.rename(self.tmpPath(), self.path())\n",
    "                self.vlog('Successful rename from %s to %s' % (self.tmpPath(),self.path()))\n",
    "            except Exception as e:\n",
    "                self.log('Received exception %s during rename' % e)\n",
    "                self.log('Run directory: %s' % self.tmpPath())\n",
    "                self.log('Settings: %s' % self.settingsAsString())\n",
    "                raise\n",
    "        self.assertComplete()\n",
    "\n",
    "    def log(self, *args, include_stdout=True):\n",
    "        prefix = '%s %s' % (os.getpid(), threading.get_ident())\n",
    "        buf = io.StringIO()\n",
    "        print(prefix, *args, file=buf)\n",
    "        if include_stdout:\n",
    "            sys.stdout.write(buf.getvalue())\n",
    "            sys.stdout.flush()\n",
    "        if self.logfile:\n",
    "            self.logfile.write(buf.getvalue())\n",
    "            self.logfile.flush()\n",
    "\n",
    "    # Log only to stdout if in verbose mode\n",
    "    def vlog(self, *args):\n",
    "        self.log(*args, include_stdout=self.verbose)\n",
    "\n",
    "    def runDispersion(self):\n",
    "        hyString = self.hysplitLoc + 'hycs_std'\n",
    "        #out = subprocess.run(hyString, shell=True)\n",
    "        subprocess_check(hyString, cwd=self.tmpPath(), verbose=True)\n",
    "\n",
    "\n",
    "    # Get the path to the uncompressed PARDUMP file\n",
    "    def getUncompressedPardump(self):\n",
    "        #old archived pardumps should be gzipped. ensure that unzipped pardump is available in folder\n",
    "        pdumps = glob.glob(self.path() + '/PARDUMP.*')\n",
    "        zipdump = glob.glob(self.path() + '/PARDUMP.*.gz')\n",
    "        if zipdump:\n",
    "            if zipdump[0][:-3] not in pdumps:\n",
    "                with gzip.open(zipdump[0], 'rb') as f_in:\n",
    "                    with open(zipdump[0][:-3], 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "            return zipdump[0][:-3]\n",
    "        else:\n",
    "            return pdumps[0]\n",
    "\n",
    "    def settingsAsString(self):\n",
    "        ret = '{'\n",
    "        ret += ','.join(['sourceLoc:[%.6f,%.6f]' % (self.source.lat, self.source.lon),\n",
    "                         'sourceHeight:[%g,%g]' % (self.source.minHeight, self.source.maxHeight),\n",
    "                         'runStartLocal:\"%s\"' % self.runStartLocal,\n",
    "                         'emitTimeHrs:%g' % self.emitTimeHrs,\n",
    "                         'runTimeHrs:%g' % self.runTimeHrs,\n",
    "                         'initdModelType:%s' % repr(self.initdModelType)])\n",
    "        ret += '}'\n",
    "        return ret\n",
    "\n",
    "    def tmpPath(self):\n",
    "        # Compute temp path unique to this instance of Python, based on PID and thread ID\n",
    "        return '%s_%d_%d.tmp' % (self.path(), os.getpid(), threading.get_ident())\n",
    "\n",
    "\n",
    "    # Compute cache pathname relative to dispersionCachePath parent\n",
    "    def localPath(self):\n",
    "        ret = os.path.join(\n",
    "            self.source.cachePath(),\n",
    "            '%s_%gh_%gh_%g' % (self.runStartLocal.strftime('%Y%m%d_%H%M%S%z'), self.emitTimeHrs, self.runTimeHrs, self.initdModelType.value))\n",
    "        if self.hourlyPardump:\n",
    "            # Minutely (P1) pardump is assumed if this field doesn't exists, for backwards compatibility\n",
    "            ret += '_P60'\n",
    "        return ret\n",
    "\n",
    "    # Compute cache pathname\n",
    "    def path(self):\n",
    "        return os.path.join(\n",
    "            dispersionCachePath,\n",
    "            self.localPath())\n",
    "\n",
    "    # Some hysplit commands can't cope with long filenames\n",
    "    # Symlink a hashed version of the path in /tmp\n",
    "    def shortPath(self):\n",
    "        fullPath = self.path()\n",
    "        linkPath = '/tmp/' + hashlib.sha224(fullPath.encode()).hexdigest()\n",
    "        if not os.path.exists(linkPath):\n",
    "            os.symlink(fullPath, linkPath)\n",
    "        return linkPath\n",
    "\n",
    "    # Possibly old code, only used for recognizing multiple runs for visualization\n",
    "    # Don't bother appending '_Pn' since we only run old visualizations on directories that have full minute-scale pardump\n",
    "    def settingsPath(self):\n",
    "        print('TODO: consider changing visualization code to no longer use settingsPath, and then delete this member fn')\n",
    "        return os.path.join(\n",
    "            dispersionCachePath,\n",
    "            '*/%s*_%gh_*_%g' % (self.runStartLocal.strftime('%Y%m%d'), self.emitTimeHrs, self.initdModelType.value))\n",
    "\n",
    "    def cdumpPath(self):\n",
    "        return self.path() + '/cdump'\n",
    "\n",
    "    def shortCdumpPath(self):\n",
    "        return self.shortPath() + '/cdump'\n",
    "\n",
    "    # outputPath can end in .ps or .png\n",
    "    # frameno is 1 for the first frame, add one for each 15 minutes as we currently run hysplit\n",
    "    def createConcPlot(self, outputPath, frameno=None, verbose=False):\n",
    "        hysplitPath = '/projects/hysplit'\n",
    "        outputSuffix = os.path.splitext(outputPath)[1]\n",
    "        convertCmds = []\n",
    "        if outputSuffix.lower() == '.ps':\n",
    "            psPath = outputPath\n",
    "        elif outputSuffix.lower() == '.png':\n",
    "            psPath = '/tmp/psconvert-%d-%d.ps' % (os.getpid(), threading.get_ident())\n",
    "            # Compute temp path unique to this instance of Python, based on PID and thread ID\n",
    "            convertCmds.append([\n",
    "                    'gmt',\n",
    "                    'psconvert',\n",
    "                    '-A',\n",
    "                    psPath,\n",
    "                    '-Tg', # PNG format\n",
    "                    '-F%s' % outputPath\n",
    "            ])\n",
    "            # Trim whitespace\n",
    "            convertCmds.append(['mogrify', '-trim', outputPath])\n",
    "        cmd = [\n",
    "            '%s/exec/concplot' % hysplitPath,\n",
    "            '-i%s' % self.shortCdumpPath(),\n",
    "            '-o%s' % psPath,\n",
    "            '-j%s/graphics/arlmap' % hysplitPath\n",
    "            ]\n",
    "        fixedConcentrations = True\n",
    "        if fixedConcentrations:\n",
    "            # Fix concentration contours in powers of ten from 1e-9 ... 1e-14\n",
    "            cmd += ['-c4', '-v1E-9+1E-10+1E-11+1E-12+1E-13+1E-14']\n",
    "        if frameno != None:\n",
    "            cmd.append('-n%d:%d' % (frameno, frameno))\n",
    "\n",
    "        subprocess_check(cmd, verbose=verbose)\n",
    "        for convertCmd in convertCmds:\n",
    "            subprocess_check(convertCmd, verbose=verbose)\n",
    "        if len(convertCmds):\n",
    "            os.unlink(psPath)\n",
    "\n",
    "    def fetchWeatherFiles(self):\n",
    "        hrrrDir = os.path.abspath('/projects/9ab71616-fcde-4524-bf8f-7953c669ebbb/air-data/hrrr')\n",
    "        fNames = []\n",
    "        isReformat = self.runStartUtc > datetime.datetime(2019,7,22,0,0,0,0,dateutil.tz.tzutc()) #date when NOAA archive format changed\n",
    "        for dt in self.computeTimes():\n",
    "            name = dt.strftime('hysplit.%Y%m%d.%Hz.hrrra')\n",
    "            fullPath = hrrrDir + '/' + name\n",
    "            if not os.path.exists(fullPath):\n",
    "                if isReformat:\n",
    "                    linkEnd = dt.strftime('%Y%m%d_%H-') + str(dt.hour + 5).zfill(2) + '_hrrr'\n",
    "                    download_file('ftp://arlftp.arlhq.noaa.gov/pub/archives/hrrr/' + linkEnd, fullPath)\n",
    "                else:\n",
    "                    download_file('ftp://arlftp.arlhq.noaa.gov/pub/archives/hrrr.v1/' + name, fullPath)\n",
    "            fNames.append(fullPath)\n",
    "        return fNames\n",
    "\n",
    "    def computeTimes(self):\n",
    "        dtimes = []\n",
    "        t = self.runStartUtc\n",
    "        cutoffTime = datetime.datetime.fromtimestamp(int((self.runStartUtc + datetime.timedelta(hours=(self.runTimeHrs+6))).timestamp()/(6*3600))*(6*3600), dateutil.tz.tzutc())\n",
    "        while(t < cutoffTime):\n",
    "            dtimes.append(datetime.datetime.fromtimestamp(int(t.timestamp() / (6*3600)) * (6*3600), dateutil.tz.tzutc()))\n",
    "            t = t + datetime.timedelta(hours = 6)\n",
    "        return dtimes\n",
    "\n",
    "    def makeSetup(self):\n",
    "        # See hysplit users guide section \"Particle File Output Options\" for ndump and ncycl\n",
    "        if self.hourlyPardump:\n",
    "            # dump after every 1 hour, cycling every 1 hour because ncycl = 1\n",
    "            ndump = 1\n",
    "        else:\n",
    "            # dump every 1 minute until entire run is done\n",
    "            ndump = -self.runTimeHrs\n",
    "        templ = Template(\n",
    "            \"\"\"&SETUP\n",
    "{#        #}NUMPAR = 2500,\n",
    "{#        #}MAXPAR = 25000,\n",
    "{#        #}INITD ={{run.initdModelType.value}},\n",
    "{#        #}CONAGE = 1,\n",
    "{#        #}KSPL = 1,\n",
    "{#        #}ndump = {{ndump}},\n",
    "{#        #}ncycl = 1,\n",
    "{#        #}delt = 1,\n",
    "{#        #}poutf = 'PARDUMP.h{{run.runStartLocal.hour}}',\n",
    "{#        #}/\\n\"\"\", keep_trailing_newline=1)\n",
    "        content = templ.render(run=self, ndump=ndump)\n",
    "        cFile = open(self.tmpPath() + '/SETUP.CFG', 'w')\n",
    "        cFile.write(content)\n",
    "        cFile.close()\n",
    "\n",
    "    def makeASC(self):\n",
    "        templ = Template(\n",
    "            \"\"\"-90.0   -180.0  lat/lon of lower left corner\n",
    "{#        #}1.0     1.0     lat/lon spacing in degrees\n",
    "{#        #}180     360     lat/lon number of data points\n",
    "{#        #}2               default land use category\n",
    "{#        #}0.2             default roughness length (m)\n",
    "{#        #}'opt/hysplit/bdyfiles/'  directory of files\"\"\")\n",
    "\n",
    "        cFile = open(self.tmpPath() + '/ASCDATA.CFG','w')\n",
    "        cFile.write(templ.render(run=self))\n",
    "        cFile.close()\n",
    "\n",
    "    def makeControl(self):\n",
    "        templ = Template(\n",
    "            \"\"\"{{ run.runStartUtc.strftime('%y %m %d %H %M') }}\t\t\t\t#1: run start time in YY MM DD HH MN (UTC)\n",
    "{#           #}2\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#2: NUMBER OF SOURCE LOCATIONS\n",
    "{#           #}{% for height in (run.source.minHeight, run.source.maxHeight) -%}\n",
    "{#           #}{{ run.source.lat }} {{ run.source.lon }} {{ height }} 1 {{ run.source.areaSqM }}\t#3: SOURCE LATITUDE | LONGITUDE | HEIGHT(m-agl) | EMISSION RATE (per hour) | AREA (sq m)\n",
    "{#           #}{%- endfor -%}\n",
    "{#           #}{{ run.runTimeHrs }}\t\t\t\t\t\t\t\t\t\t\t#4: TOTAL RUN TIME (hours)\n",
    "{#           #}0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#5: VERTICAL MOTION (USE MODEL VERTICAL VELOCITY)\n",
    "{#           #}10000\t\t\t\t\t\t\t\t\t\t\t\t\t\t#6: TOP OF MODEL DOMAIN (m-AGL)\n",
    "{#           #}{{ len(run.fNames) }}\t\t\t\t\t\t\t\t\t\t#7: NUMBER OF INPUT DATA GRIDS\n",
    "{#           #}{% for file in run.fNames -%}\n",
    "{#           #}{{ os.path.dirname(file) }}/\n",
    "{#           #}{{ os.path.basename(file) }}\n",
    "{#           #}{%- endfor -%}\n",
    "{#           #}1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#10: NUMBER OF DIFFERENT POLLUTANTS\n",
    "{#           #}TEST\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#11: POLLUTANT IDENTIFICATION\n",
    "{#           #}1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#12: EMISSION RATE (per hour)\n",
    "{#           #}{{run.emitTimeHrs}}\t\t\t\t\t\t\t\t\t\t\t\t#13: HOURS OF EMISSION\n",
    "{#           #}{{run.runStartUtc.strftime('%y %m %d %H %M')}}\t\t\t\t\t#14: EMISSION START TIME: YY mm dd HH MM\n",
    "{#           #}1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#15: NUMBER OF CONCENTRATION GRIDS\n",
    "{#           #}0 0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#16: CONC GRID CENTER (LATITUDE LONGITUDE); DEFAULT SOURCE LOC\n",
    "{#           #}0.003 0.003\t\t\t\t\t\t\t\t\t\t\t\t\t#17: CONC GRID SPACING (degrees) LATITUDE LONGITUDE\n",
    "{#           #}1 1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#18: CONC GRID SPAN (degrees) LATITUDE LONGITUDE\n",
    "{#           #}./\n",
    "{#           #}{{run.fileName}}\n",
    "{#           #}1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#21: NUMBER OF VERTICAL CONCENTRATION LEVELS\n",
    "{#           #}100\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#22: HEIGHT OF EACH CONCENTRATION LEVEL (m-agl)\n",
    "{#           #}{{run.runStartUtc.strftime('%y %m %d %H %M')}}\t\t\t\t\t#23: SAMPLING START TIME:YEAR MONTH DAY HOUR MINUTE\n",
    "{#           #}00 00 00 {{run.runHr}} {{run.runMin}}\t\t\t\t\t\t\t#24: SAMPLING STOP TIME:YEAR MONTH DAY HOUR MINUTE\n",
    "{#           #}0 0 15\t\t\t\t\t\t\t\t\t\t\t\t\t\t#25: SAMPLING INTERVAL: TYPE (AVERAGING) HOUR MINUTE\n",
    "{#           #}0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#26: NUMBER OF DEPOSITING POLLUTANTS\n",
    "{#           #}0.0 0.0 0.0\t\t\t\t\t\t\t\t\t\t\t\t\t#27: PARTICLE:DIAMETER (um), DENSITY (g/cc), SHAPE\n",
    "{#           #}0.0 0.0 0.0 0.0 0.0\t\t\t\t\t\t\t\t\t\t\t#28: ATTRIBUTES, ZERO (NO DEPOSITING)\n",
    "{#           #}0.0 0.0 0.0\t\t\t\t\t\t\t\t\t\t\t\t\t#29: WET REMOVAL, ZERO (NO DEPOSITING)\n",
    "{#           #}0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#30: RADIOACTIVE DECAY HALF-LIFE (days)\n",
    "{#           #}0.0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#31: POLLUTANT RESUSPENSION\"\"\")    \n",
    "\n",
    "        cFile = open(self.tmpPath() + '/CONTROL', 'w')\n",
    "        cFile.write(templ.render(run=self, os=os, len=len))\n",
    "        cFile.close()\n",
    "\n",
    "    def saveToText(self, name):\n",
    "        # -s: Single file output\n",
    "        # -c: output all information from binary (does not work with -s set)\n",
    "        # -m: if -s isn't set, removes column headers from output file\n",
    "        # -t: if -s and -c aren't set, includes minutes in file name\n",
    "        # -v: order lon/lat\n",
    "        # -x: Extended precision\n",
    "        # -z: Include zeros\n",
    "        hyString = self.hysplitLoc + ('con2asc -i%s -s -t -v -x -z' %name)\n",
    "        out = subprocess.run(hyString, cwd=(self.tmpPath()), shell=True)\n",
    "\n",
    "    def interpolate(self, cdumpFile, outputFile, stationFile):\n",
    "        #subprocess_check('ls -l %s %s' % (cdumpFile, stationFile), verbose=True)\n",
    "        #subprocess_check('cat %s' % stationFile, verbose=True)\n",
    "        hyString = self.hysplitLoc + ('con2stn -i%s -o%s -s%s' %(cdumpFile, outputFile, stationFile))\n",
    "        #print(hyString)\n",
    "        subprocess_check(hyString, cwd=(self.path()))\n",
    "        #print('done interpolation')\n",
    "\n",
    "\n",
    "    # reads in result of hysplit interpolation\n",
    "    # simplifies into single average timestamp and returns DataFrame\n",
    "    # input:\n",
    "    #   inFile -- path and filename of hysplit interpolation results\n",
    "    # output:\n",
    "    #   interpDat -- DataFrame with index = timestamps, columns = sensor IDs\n",
    "    def readInterpFile(self,inFile,sensors):\n",
    "        #print('readInterFile reading from %s' % inFile)\n",
    "        #subprocess_check('wc %s' % inFile, verbose=True)\n",
    "        fIn = pd.read_csv(inFile, header=0, delimiter='\\s+')\n",
    "\n",
    "        timestamps = []\n",
    "\n",
    "        for ii in np.arange(fIn.shape[0]):\n",
    "            t1 = datetime.datetime(2000 + fIn['YR'][ii], fIn['MO'][ii], fIn['DA1'][ii], fIn['HR1'][ii], fIn['MN1'][ii], tzinfo=datetime.timezone.utc)\n",
    "            t2 = datetime.datetime(2000 + fIn['YR'][ii], fIn['MO'][ii], fIn['DA2'][ii], fIn['HR2'][ii], fIn['MN2'][ii], tzinfo=datetime.timezone.utc)\n",
    "            timestamps.append((t1 + (t2 - t1)/2).timestamp() * 1e9) #convert timestamp to nanoseconds so it can be converted to pandas datetime64 object\n",
    "\n",
    "        interpDat = pd.DataFrame(data=fIn.iloc[:,9:])\n",
    "        interpDat.index = pd.to_datetime(timestamps, utc=True).tz_convert(self.runStartLocal.tzinfo)\n",
    "\n",
    "        sensorIDdict = {str(sensor.id()): sensor for sensor in sensors}\n",
    "        interpDat = interpDat.rename(columns=sensorIDdict)\n",
    "\n",
    "        return interpDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def getDispersionRun(source,runStartLocal,emitTimeHrs,runTimeHrs,hysplitModelSettings,verbose=False):\n",
    "    run = CachedDispersionRun(\n",
    "            source=source,\n",
    "            runStartLocal=runStartLocal,\n",
    "            emitTimeHrs=emitTimeHrs,\n",
    "            runTimeHrs=runTimeHrs,\n",
    "            hysplitModelSettings=hysplitModelSettings,\n",
    "            verbose=verbose\n",
    "    )\n",
    "    run.findOrRun()\n",
    "    run.assertComplete()\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#TODO: Change to only return \n",
    "#only used for visualization (currently)\n",
    "#use threading to produce collection of DispersionRuns over several hours for the same source\n",
    "#TODO: check if resolutionHrs param is redundant with emitTimeHrs (check old linRegLib method). not urgent as long as both are always 1\n",
    "def getMultiHourDispersionRunsParallel(source,runStartLocal,emitTimeHrs,totalRunTimeHrs,hysplitModelSettings,backwardsHrs=0,resolutionHrs=1):\n",
    "    hysplitStartLocal = runStartLocal - datetime.timedelta(hours=backwardsHrs)\n",
    "    hysplitRunTimeHrs = totalRunTimeHrs + backwardsHrs\n",
    "    \n",
    "    hours = list(dateutil.rrule.rrule(dateutil.rrule.HOURLY, interval=resolutionHrs, dtstart=hysplitStartLocal, until=runStartLocal + datetime.timedelta(hours=totalRunTimeHrs-1)))\n",
    "\n",
    "    #TODO: switch to process pool?\n",
    "    maxThreads = 30\n",
    "    pool = SimpleThreadPoolExecutor(maxThreads)\n",
    "    for i,hour in enumerate(hours):\n",
    "        run = CachedDispersionRun(\n",
    "            source=source,\n",
    "            runStartLocal=hour,\n",
    "            emitTimeHrs=emitTimeHrs,\n",
    "            runTimeHrs=min(hysplitRunTimeHrs-(i*resolutionHrs),24),\n",
    "            hysplitModelSettings=hysplitModelSettings\n",
    "            )\n",
    "        pool.submit(run.findOrRun)\n",
    "    pathList = pool.shutdown()\n",
    "    return pathList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}