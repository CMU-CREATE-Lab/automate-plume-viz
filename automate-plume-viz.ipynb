{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import re, array, csv, datetime, glob, json, math, random, stat\n",
    "import pytz, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "# This is a utility function for running other ipython notebooks\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "\n",
    "# Load utility functions from another ipython notebook\n",
    "root_dir = \"/projects/9ab71616-fcde-4524-bf8f-7953c669ebbb/air-src/\"\n",
    "os.chdir(root_dir + \"linRegModel/pardump_example/\")\n",
    "exec_ipynb(\"pardumpdump-randy-amy-util.ipynb\")\n",
    "os.chdir(root_dir + \"linRegModel\")\n",
    "exec_ipynb(\"./cachedHysplitRunLib.ipynb\")\n",
    "exec_ipynb(\"../../src/python-utils/utils.ipynb\")\n",
    "os.chdir(root_dir + \"automate-plume-viz/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Specify the starting and ending date, also the time offset\n",
    "start = \"2019-01-01\"\n",
    "end = \"2020-01-01\"\n",
    "offset = pd.Timedelta(3, unit=\"h\")\n",
    "\n",
    "# Create rows in the EarthTime document\n",
    "start_d = pd.date_range(start=start, end=end, closed=\"left\", tz=\"US/Eastern\") - offset\n",
    "end_d = pd.date_range(start=start, end=end, closed=\"right\", tz=\"US/Eastern\") - offset\n",
    "df_template = pd.read_csv(\"data/earth_time_template.csv\")\n",
    "df = df_repeated = pd.concat([df_template]*len(start_d), ignore_index=True)\n",
    "file_name = \"plume_\" + end_d.strftime(\"%Y%m%d\")\n",
    "df[\"Start date\"] = start_d.tz_convert(\"UTC\").strftime(\"%Y%m%d%H%M%S\")\n",
    "df[\"End date\"] = end_d.tz_convert(\"UTC\").strftime(\"%Y%m%d%H%M%S\")\n",
    "df[\"Share link identifier\"] = file_name\n",
    "df[\"Name\"] = \"PARDUMP \" + end_d.strftime(\"%Y-%m-%d\")\n",
    "df[\"URL\"] = \"https://cocalc-www.createlab.org/pardumps/\" + file_name + \".bin\"\n",
    "\n",
    "# Save rows of EarthTime CSV layers to a file so that we can copy and paste\n",
    "p = \"data/earth_time.csv\"\n",
    "df.to_csv(p, index=False)\n",
    "os.chmod(p, 0o777)\n",
    "\n",
    "# Create rows of share URLs\n",
    "et_root_url = \"https://davos2019.earthtime.org/explore#\"\n",
    "et_part = \"v=581806,708156,584252,710601,pts&ps=2000&startDwell=0&endDwell=0\"\n",
    "ts_root_url = \"https://thumbnails-earthtime.cmucreatelab.org/thumbnail?\"\n",
    "ts_part = \"&width=720&height=720&format=mp4&fps=30&tileFormat=mp4&startDwell=0&endDwell=0&fromScreenshot&timestampOnlyUILeft\"\n",
    "url_ls = [] # original EarthTime url\n",
    "thumb_url_ls = [] # thumbnail server url\n",
    "for index, row in df.iterrows():\n",
    "    # Add the original url\n",
    "    bt = \"bt=\" + row[\"Start date\"] + \"&\"\n",
    "    et = \"et=\" + row[\"End date\"] + \"&\"\n",
    "    l = \"l=bdrk,smell_my_city_pgh_reports,plume_\" + row[\"Start date\"][:8] + \"&\"\n",
    "    full_url = et_root_url + l + bt + et + et_part\n",
    "    url_ls.append(full_url)\n",
    "    # Add the thumbnail server url\n",
    "    rt = \"root=\" + urllib.parse.quote(full_url, safe=\"\") + \"&\"\n",
    "    thumb_url_ls.append(ts_root_url + rt + ts_part)\n",
    "df_url = pd.DataFrame(data={\"url\": url_ls, \"thumbnail_url\": thumb_url_ls})\n",
    "\n",
    "# Save rows of EarthTime urls to a file\n",
    "p = \"data/earth_time_urls.csv\"\n",
    "df_url.to_csv(p, index=False)\n",
    "os.chmod(p, 0o777)\n",
    "print(df_url[\"url\"][91])\n",
    "print(df_url[\"thumbnail_url\"][91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Location of the sources of pollution\n",
    "sources = [\n",
    "    DispersionSource(name='Irvin',lat=40.328015, lon=-79.903551, minHeight=0, maxHeight=50),\n",
    "    DispersionSource(name='ET',lat=40.392967, lon=-79.855709, minHeight=0, maxHeight=50),\n",
    "    DispersionSource(name='Clairton',lat=40.305062, lon=-79.876692, minHeight=0, maxHeight=50),\n",
    "    DispersionSource(name='Cheswick',lat=40.538261, lon=-79.790391, minHeight=0, maxHeight=50),\n",
    "]\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "#   start_time_eastern: for different dates, use format \"2020-03-30 00:00\"\n",
    "#   o_file: file name to save the simulation result\n",
    "#   sources: location of the sources of pollution\n",
    "#   emit_time_hrs:  affects the emission time for running each Hysplit model\n",
    "#   duration: total time (in hours) for the simulation, use 24 for a total day, use 12 for testing\n",
    "def simulate(start_time_eastern, o_file, sources=sources, emit_time_hrs=1, duration=24):\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(\"start_time_eastern: %s\" % start_time_eastern)\n",
    "    print(\"o_file: %s\" % o_file)\n",
    "    # Run simulation and get the folder list (the generated files are cached)\n",
    "    path_list = []\n",
    "    for source in sources:\n",
    "        path_list += getMultiHourDispersionRunsParallel(\n",
    "                source,\n",
    "                parse_eastern(start_time_eastern),\n",
    "                emit_time_hrs,\n",
    "                duration,\n",
    "                HysplitModelSettings(initdModelType=InitdModelType.ParticleHV, hourlyPardump=False))\n",
    "    print(path_list)\n",
    "    # Save pdump text files (the generated files are cached)\n",
    "    pdump_txt_list = []\n",
    "    for folder in path_list:\n",
    "        if not findInFolder(folder,'*.gz') and not findInFolder(folder,'PARDUMP*.txt'):\n",
    "            pdump = findInFolder(folder,'PARDUMP.*')\n",
    "            print(pdump)\n",
    "            cmd = \"/opt/hysplit/exec/par2asc -i%s -o%s\" % (pdump, pdump+\".txt\")\n",
    "            #cmd = f\"/opt/hysplit/exec/par2asc -i{pdump} -o{pdump}.txt\"\n",
    "            if pdump.find('.txt') == -1:\n",
    "                pdump_txt_list.append(pdump+\".txt\")\n",
    "            subprocess_check(cmd)\n",
    "        if findInFolder(folder,'PARDUMP*.txt'):\n",
    "            pdump_txt = findInFolder(folder,'PARDUMP*.txt')\n",
    "            pdump_txt_list.append(pdump_txt)\n",
    "    print(pdump_txt_list)\n",
    "    # Add color\n",
    "    cmap = \"viridis\"\n",
    "    c = plt.get_cmap(cmap)\n",
    "    c.colors\n",
    "    colors = np.array(c.colors)\n",
    "    colors *= 255\n",
    "    colormap = np.uint8(colors.round())\n",
    "    colormap = colormap.reshape([1,256,3])\n",
    "    cmaps = [\n",
    "        [[250, 255, 99]],\n",
    "        [[250, 255, 99],[99, 255, 206]],\n",
    "        [[250, 255, 99],[99, 255, 206],[206, 92, 247]],\n",
    "        [[250, 255, 99],[99, 255, 206],[206, 92, 247],[255, 119, 0]]\n",
    "    ]\n",
    "    print(\"Creating %s\" % o_file)\n",
    "    points = create_multisource_bin(pdump_txt_list, o_file, len(sources), False, cmaps, duration)\n",
    "    print(\"Created %s\" % o_file)\n",
    "    os.chmod(o_file, 0o777)\n",
    "\n",
    "\n",
    "# Prepare the list of dates for running the simulation\n",
    "start_time_eastern_all = start_d.strftime(\"%Y-%m-%d %H:%M\").values\n",
    "o_root = \"/projects/cocalc-www.createlab.org/pardumps/\"\n",
    "o_file_all = o_root + file_name.values + \".bin\"\n",
    "\n",
    "# For each date, run the simulation\n",
    "#for i in range(len(start_time_eastern_all)):\n",
    "for i in [91,112]: # for testing purposes\n",
    "    if os.path.isfile(o_file_all[i]): # skip if the file exists\n",
    "        print(\"File already exists %s\" % o_file_all[i])\n",
    "        continue\n",
    "    simulate(start_time_eastern_all[i], o_file_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python 3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}